---
title: "DATS 6450 – Reinforcement Learning"
author: "Tyler Wallett, MS & Amir Jafari, PhD"
date: "today"
format: 
  html:
    number-sections: false
---

```{=html}
<div class="slideshow-container">
  <div class="slideshow">
    <div class="slide">
      <img src="data/images/breakout.gif" />
      <figcaption>Breakout (Lecture 8)</figcaption>
    </div>
    <div class="slide">
      <img src="data/images/cheetah.gif" />
      <figcaption>Cheetah (Lecture 10)</figcaption>
    </div>
    <div class="slide">
      <img src="data/images/gridworld.gif" />
      <figcaption>Gridworld (Lectures 4-6)</figcaption>
    </div>
    <div class="slide">
      <img src="data/images/highway.gif" />
      <figcaption>Highway (Lecture 8)</figcaption>
    </div>
  </div>
</div>

<style>
  .slideshow-container {
    width: 100%;
    overflow: hidden;
    position: relative;
    display: flex;
    justify-content: center;
  }

  .slideshow {
    display: flex;
    width: 100%;
    animation: slide 16s ease-in-out infinite;
  }

  .slide {
    width: 100%;
    flex-shrink: 0;
    text-align: center;
    display: flex;
    flex-direction: column;
    align-items: center;
  }

  .slide img {
    width: 120%;
    max-width: 415px;
    height: auto;
    margin: auto;
  }

  figcaption {
    font-size: 14px;
    margin-top: 5px;
  }

  @keyframes slide {
    0%, 20% { transform: translateX(0); }
    25%, 45% { transform: translateX(-100%); }
    50%, 70% { transform: translateX(-200%); }
    75%, 95% { transform: translateX(-300%); }
    100% { transform: translateX(0); }
  }
</style>

```

## Instructor Information

::: {.grid}

::: {.g-col-12 .g-col-md-4 .text-center}
![](data/images/me.png){width=200 height=250}
:::

::: {.g-col-12 .g-col-md-8}
- **Name:** Tyler Wallett, M.S.  
- **Term:** Fall 2025  
- **Office location:** Samson Hall Room 310  
- **Office hours:** TBD  
- **E-mail:** [twallett@gwu.edu](mailto:twallett@gwu.edu)  
- **Github:** [twallett](https://github.com/twallett)  
- **Zoom:** Meeting Link  
:::

:::

## Course Description

The aim of this course is to provide a comprehensive understanding of the **reinforcement learning framework**. The course will explore the key distinctions between reinforcement learning and other artificial intelligence learning paradigms, delve into relevant industry applications, and examine both classical and deep learning approaches. Additionally, the course will cover the taxonomy of reinforcement learning and offer hands-on experience through practical implementations using OpenAI Gymnasium and other learning environments.

The **classical approach** will focus on learning methods designed to find optimal solutions in tabular environments, whereas the **deep learning approach** will tackle the challenge of finding approximate optimal solutions in large or continuous environments through the use of deep learning architectures.

The course will introduce the **taxonomy of reinforcement learning** by focusing on model-free value-based methods, transitioning to value function approximation and deep learning approaches, followed by novel policy-based methods using state-of-the-art architectures to tackle complex environments.

To conclude, a discussion on **advanced topics, applications, and outlook** of reinforcement learning will be provided.

## Learning Outcomes

1. Implement Reinforcement Learning frameworks using `numpy` and `tensorflow`. <br>
2. Design decision-making systems using classical and deep learning architectures. <br>
3. Explain the Reinforcement Learning taxonomy. <br>
4. Identify Reinforcement Learning’s challenges, current research, and future outlook. 

## Resources

- *Reinforcement Learning: An Introduction* by Richard S. Sutton and Andrew G. Barto ([Web Link](https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf))

## Software Requirements

- **Programming:** Python.
  
```bash
pip install numpy
pip install tensorflow
pip install pygame
pip install gymnasium
pip install stable-baselines3
```

- **Cloud Services:** Google Colab.

## Course Outline

| Week             | Topic                                      | Quiz/Exams      | Subjects                                             |
|------------------|--------------------------------------------|-----------------|------------------------------------------------------|
| Aug 29, 2025 | Introduction to Reinforcement Learning | | - Course Outline  <br> - Why should I study Reinforcement Learning? <br> - What is Reinforcement Learning?  <br> - Where is Reinforcement Learning Applied?  <br> - How is Reinforcement Learning Structured? <br>|
| Sep 5, 2025  | Mathematical Foundations       | | - Set Theory <br> - Axiomatic Probability <br> - Conditioning <br> - Independence <br> - Random Variables <br> - Expectation <br> - Probability Distribution |
| Sep 12, 2025 | Multi-Armed Bandits            | Quiz 1      | - Multi-Armed Bandit Framework  <br> - $\epsilon$-Greedy  <br> - Upper Confidence Boundary (UCB) <br> - Thompson Sampling |
| Sep 19, 2025 | Dynamic Programming            | Quiz 2      | - Markov Chain <br> - Markov Decision Process <br> - Bellman Equations <br> - Dynamic Programming |
| Sep 26, 2025 | Monte Carlo Methods            | Quiz 3      | - OpenAI Gymansium Environment: GridWorld <br> - On-Policy Monte Carlo  <br> - Off-Policy Monte Carlo |
| Oct 3, 2025  | Temporal-Difference            | Quiz 4      | - OpenAI Gymansium Environment: GridWorld <br> - Temporal Difference Prediction <br> - SARSA  <br> - Q-Learning  <br> - Double Q-Learning <br> - (Optional) n-step TD|
| Oct 10, 2025 | Function Approximation         | **Exam 1**  | - OpenAI Gymansium Environment: MountainCar <br> - Value Function Approximation (VFA) <br> - On-Policy Function Approximation <br> - Semi-gradient SARSA <br> - Limitations of Off-Policy Function Approximation |
| Oct 24, 2025 | Deep Q-Networks                | Quiz 5      | - OpenAI Gymansium Environment: BreakOut <br> - Multi-Layered Perceprtons (MLPs) <br> - Convolutional Neural Networks (CNNs) <br> - Experience Replay  <br> - Fixed Targets <br> - Vanilla Deep Q-Network |
| Oct 31, 2025  | Policy Gradients               | Quiz 6      | - OpenAI Gymansium Environment: CartPole <br> - Policy Gradient Theorem  <br> - Vanilla Policy Gradient |
| Nov 7, 2025 | Advanced Policy Gradients      | Quiz 7      | - OpenAI Gymansium Environment: HalfCheetah <br> - Trust Region Policy Optimization (TRPO) <br> - Proximal Policy Optimization: KL-Divergence <br> - Proximal Policy Optimization: Clip |
| Nov 14, 2025 | **Thanksgiving Break**         |             |                                                                          |
| Nov 21, 2025 | Monte Carlo Tree Search        | **Exam 2**  | - OpenAI Gymansium Environment: Tic Tac Toe <br> - Model-based Reinforcement Learning <br> - Monte Carlo Tree Search <br> - AlphaGo <br> - MuZero |
| Oct 28, 2025 | Conclusion                     |             |                                                                          |
| Dec 5, 2025  | Final Project Submission       |             |                                                                          |

## Prerequisites

- **DATS 6101** - Introduction to Data Science 

## Assignments & Grading

| Assignment                    | Points |
|:------------------------------:|:------:|
| Quizzes (5 best scores)    |   25   |
| Exam 1                     |   25   |
| Exam 2                     |   25   |
| Final Project              |   25   |

::: {.callout-note}
## Average Learning Per Week
Students are expected to spend a minimum of 100 minutes of out-of-class work for every 50 minutes of direct instruction, for a minimum total of 2.5 hours a week. A 3-credit course should include 2.5 hours of direct instruction and a minimum of 5 hours of independent learning or 7.5 hours per week.
:::

::: {.callout-note}
## Online Resources 
For technical requirements and support, student services, obtaining a GWorld card, and state contact information please check [HERE](online.gwu.edu/student-support)
:::

::: {.callout-note}
## Classroom Recording 
The particular class recordings will be available to students who are registered on an individual basis, upon request. Please let me know in advance if you have any medical issues or emergencies that will prevent you from joining the class.
:::

::: {.callout-tip}
## Virtual Academic Support
A full range of academic support is offered virtually in fall 2020. See [HERE](coronavirus.gwu.edu/top-faqs) for updates. Tutoring and course review sessions are offered through Academic Commons in an online format. See [HERE](academiccommons.gwu.edu/tutoring). Writing and research consultations are available online. See [HERE](academiccommons.gwu.edu/writing-research-help). Coaching, offered through the Office of Student Success, is available in a virtual format. See [HERE](studentsuccess.gwu.edu/academic-program-support). Academic Commons offers several short videos addressing different virtual learning strategies for the unique circumstances of the fall 2020 semester. See [HERE](academiccommons.gwu.edu/study-skills). They also offer a variety of live virtual workshops to equip students with the tools they need to succeed in a virtual environment. See [HERE](tinyurl.com/gw-virtual-learning).
:::

::: {.callout-warning}
## Safety and Security
In an emergency: call GWPD 202-994-6111 or 911. For situation-specific actions: review the Emergency Response Handbook in [HERE](safety.gwu.edu/emergency-response-handbook). In an active violence situation: Get Out, Hide Out, or Take Out. See [HERE](go.gwu.edu/shooterpret). Stay informed: safety.gwu.edu/stay-informed.
:::