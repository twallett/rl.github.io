project:
  type: book
  output-dir: docs

book:
  favicon: data/images/rl-logo.png
  sidebar:
    title: false
    logo: data/images/rl-logo.png
    collapse-level: 1
  chapters:
    - index.qmd
    - part: "Lecture 1: Introduction"
      chapters:
        - text: "1.1 Why should I study Reinforcement Learning?"
          file: lecture1/lecture1-1.qmd
        - text: "1.2 What is Reinforcement Learning?"
          file: lecture1/lecture1-2.qmd
        - text: "1.3 Where is Reinforcement Learning Applied?"
          file: lecture1/lecture1-3.qmd
        - text: "1.4 How is Reinforcement Learning Structured?"
          file: lecture1/lecture1-4.qmd
    - part: "Lecture 2: Mathematical Foundations"
      chapters:
        - text: "Learning Objectives"
          file: lecture2/lo.qmd
        - text: "2.1 Set Theory"
          file: lecture2/lecture2-1.qmd
        - text: "2.2 Axiomatic Probability"
          file: lecture2/lecture2-2.qmd
        - text: "2.3 Conditioning"
          file: lecture2/lecture2-3.qmd
        - text: "2.4 Independence"
          file: lecture2/lecture2-4.qmd
        - text: "2.5 Discrete Random Variables"
          file: lecture2/lecture2-5.qmd
        - text: "2.6 Continuous Random Variables"
          file: lecture2/lecture2-6.qmd
        - text: "2.7 Probability Distributions"
          file: lecture2/lecture2-7.qmd
    - part: "Lecture 3: Multi-Armed Bandits"
      chapters:
        - text: "Learning Objectives"
          file: lecture3/lo.qmd
        - text: "3.1 Multi-Armed Bandit Framework"
          file: lecture3/lecture3-1.qmd
        - text: "3.2 &epsilon;-Greedy"
          file: lecture3/lecture3-2.qmd
        - text: "3.3 Upper Confidence Boundary (UCB)"
          file: lecture3/lecture3-3.qmd
        - text: "3.4 Thompson Sampling"
          file: lecture3/lecture3-4.qmd
    - part: "Lecture 4: Dynamic Programming"
      chapters:
        - text: "Learning Objectives"
          file: lecture4/lo.qmd
        - text: "4.1 Markov Chain"
          file: lecture4/lecture4-1.qmd
        - text: "4.2 Markov Decision Process (MDPs)"
          file: lecture4/lecture4-2.qmd
        - text: "4.3 Dynamic Programming"
          file: lecture4/lecture4-3.qmd
    - part: "Lecture 5: Monte Carlo"
      chapters:
        - text: "Learning Objectives"
          file: lecture5/lo.qmd
        - text: "5.1 Monte Carlo Prediction"
          file: lecture5/lecture5-1.qmd
        - text: "5.2 Exploring Starts Monte Carlo"
          file: lecture5/lecture5-2.qmd
        - text: "5.3 On-Policy Monte Carlo"
          file: lecture5/lecture5-3.qmd
        - text: "5.4 Off-Policy Monte Carlo"
          file: lecture5/lecture5-4.qmd
    - part: "Lecture 6: Temporal Difference"
      chapters:
        - text: "Learning Objectives"
          file: lecture6/lo.qmd
        - text: "6.1 Temporal Difference (TD) Prediction"
          file: lecture6/lecture6-1.qmd
        - text: "6.2 SARSA"
          file: lecture6/lecture6-2.qmd
        - text: "6.3 Q-Learning"
          file: lecture6/lecture6-3.qmd
        - text: "6.4 Double Q-Learning"
          file: lecture6/lecture6-4.qmd
        # - text: "6.5 (Optional) n-step Bootstrapping"
        #   file: lecture6/lecture6-5.qmd
    - part: "Lecture 7: Function Approximation"
      chapters:
        - text: "Learning Objectives"
          file: lecture7/lo.qmd
        - text: "7.1 Value Function Approximation"
          file: lecture7/lecture7-1.qmd
        - text: "7.2 On-Policy Function Approximation"
          file: lecture7/lecture7-2.qmd
        - text: "7.3 Off-Policy Function Approximation"
          file: lecture7/lecture7-3.qmd
    - part: "Lecture 8: Deep Q-Networks (DQN)"
      chapters:
        - text: "Learning Objectives"
          file: lecture8/lo.qmd
        - text: "8.1 Deep Learning"
          file: lecture8/lecture8-1.qmd
        - text: "8.2 Deep Q-Networks"
          file: lecture8/lecture8-2.qmd
    - part: "Lecture 9: Policy Gradients"
      chapters:
        - text: "Learning Objectives"
          file: lecture9/lo.qmd
        - text: "9.1 Policy Gradients"
          file: lecture9/lecture9-1.qmd
    - part: "Lecture 10: Advanced Policy Gradients"
      chapters:
        - text: "Learning Objectives"
          file: lecture10/lo.qmd
        - text: "10.1 Trust Region Policy Optimization (TRPO)"
          file: lecture10/lecture10-1.qmd
        - text: "10.2 Proximal Policy Optimization (PPO)"
          file: lecture10/lecture10-2.qmd
    - part: "Lecture 11: Monte Carlo Tree Search"
      chapters:
        - text: "Learning Objectives"
          file: lecture11/lo.qmd
        - text: "11.1 Monte Carlo Tree Search (MCTS)"
          file: lecture11/lecture11-1.qmd
        - text: "11.2 Advanced Monte Carlo Tree Search"
          file: lecture11/lecture11-2.qmd
    - part: "Lecture 12: Conclusion"
      chapters:
        - text: "Learning Objectives"
          file: lecture12/lo.qmd
        - text: "12.1 Advanced Topics in Reinforcement Learning"
          file: lecture12/lecture12-1.qmd
        - text: "12.2 Identify the Reinforcement Learning Application"
          file: lecture12/lecture12-2.qmd
        - text: "12.3 Outlook of Reinforcement Learning"
          file: lecture12/lecture12-3.qmd
    - part: "Homeworks"
      chapters:
        - text: "Homework 1"
          file: homework/homework1.qmd
        - text: "Homework 2"
          file: homework/homework2.qmd
        - text: "Homework 3"
          file: homework/homework3.qmd
        - text: "Homework 4"
          file: homework/homework4.qmd
        - text: "Homework 5"
          file: homework/homework5.qmd
        - text: "Homework 6"
          file: homework/homework6.qmd
        - text: "Homework 7"
          file: homework/homework7.qmd
        - text: "Homework 8"
          file: homework/homework8.qmd
        - text: "Homework 9"
          file: homework/homework9.qmd
        - text: "Homework 10"
          file: homework/homework10.qmd
        - text: "Homework 11"
          file: homework/homework11.qmd
        - text: "Homework 12"
          file: homework/homework12.qmd
    - references.qmd

bibliography: references.bib

format:
  html:
    bread-crumbs: false
    number-sections: false
    grid:
      body-width: 1000px
      sidebar-width: 320px
  pdf:
    documentclass: scrreprt

filters:
  - pseudocode