project:
  type: book
  output-dir: docs

book:
  favicon: data/images/rl-logo.png
  sidebar:
    title: false
    logo: data/images/rl-logo.png
    collapse-level: 1
  chapters:
    - index.qmd
    - part: "Lecture 1: Introduction"
      chapters:
        - text: "1.1 Why should I study Reinforcement Learning?"
          file: lecture1/lecture1-1.qmd
        - text: "1.2 What is Reinforcement Learning?"
          file: lecture1/lecture1-2.qmd
        - text: "1.3 Where is Reinforcement Learning Applied?"
          file: lecture1/lecture1-3.qmd
        - text: "1.4 How is Reinforcement Learning Structured?"
          file: lecture1/lecture1-4.qmd
    - part: "Lecture 2: Mathematical Foundations"
      chapters:
        - text: "Learning Objectives"
          file: lecture2/lo.qmd
        - text: "2.1 Set Theory"
          file: lecture2/lecture2-1.qmd
        - text: "2.2 Axiomatic Probability"
          file: lecture2/lecture2-2.qmd
        - text: "2.3 Conditioning"
          file: lecture2/lecture2-3.qmd
        - text: "2.4 Independence"
          file: lecture2/lecture2-4.qmd
        - text: "2.5 Discrete Random Variables"
          file: lecture2/lecture2-5.qmd
        - text: "2.6 Continuous Random Variables"
          file: lecture2/lecture2-6.qmd
        - text: "2.7 Probability Distributions"
          file: lecture2/lecture2-7.qmd
    - part: "Lecture 3: Multi-Armed Bandits"
      chapters:
        - text: "Learning Objectives"
          file: lecture3/lo.qmd
        - text: "3.1 Multi-Armed Bandit Framework"
          file: lecture3/lecture3-1.qmd
        - text: "3.2 &epsilon;-Greedy"
          file: lecture3/lecture3-2.qmd
        - text: "3.3 Upper Confidence Boundary (UCB)"
          file: lecture3/lecture3-3.qmd
        - text: "3.4 Thompson Sampling"
          file: lecture3/lecture3-4.qmd
    - part: "Lecture 4: Dynamic Programming"
      chapters:
        - text: "Learning Objectives"
          file: lecture4/lo.qmd
        - text: "4.1 Markov Chain"
          file: lecture4/lecture4-1.qmd
        - text: "4.2 Markov Decision Process (MDPs)"
          file: lecture4/lecture4-2.qmd
        - text: "4.3 Dynamic Programming"
          file: lecture4/lecture4-3.qmd
    - part: "Lecture 5: Monte Carlo"
      chapters:
        - text: "Learning Objectives"
          file: lecture5/lo.qmd
        - text: "5.1 Monte Carlo Prediction"
          file: lecture5/lecture5-1.qmd
        - text: "5.2 Exploring Starts Monte Carlo"
          file: lecture5/lecture5-2.qmd
        - text: "5.3 On-Policy Monte Carlo"
          file: lecture5/lecture5-3.qmd
        - text: "5.4 Off-Policy Monte Carlo"
          file: lecture5/lecture5-4.qmd
    - part: "Lecture 6: Temporal Difference"
      chapters:
        - text: "Learning Objectives"
          file: lecture6/lo.qmd
        - text: "6.1 Temporal Difference (TD) Prediction"
          file: lecture6/lecture6-1.qmd
        - text: "6.2 SARSA"
          file: lecture6/lecture6-2.qmd
        - text: "6.3 Q-Learning"
          file: lecture6/lecture6-3.qmd
        - text: "6.4 Double Q-Learning"
          file: lecture6/lecture6-4.qmd
        - text: "6.5 (Optional) n-step Bootstrapping"
          file: lecture6/lecture6-5.qmd
    - part: "Homeworks"
      chapters:
        - text: "Homework 1"
          file: homework/homework1.qmd
        - text: "Homework 2"
          file: homework/homework2.qmd
        - text: "Homework 3"
          file: homework/homework3.qmd
        - text: "Homework 4"
          file: homework/homework4.qmd
        - text: "Homework 5"
          file: homework/homework5.qmd
        - text: "Homework 6"
          file: homework/homework6.qmd
    - references.qmd
    # - part: "Lecture 7: Function Approximation"
    #   chapters:
    #     - text: "2.1 Introduction to ML"
    #       file: index.qmd
    #     - text: "2.2 Neural Networks"
    #       file: index.qmd  
    # - part: "Lecture 8: Deep Q-Networks"
    #   chapters:
    #     - text: "2.1 Introduction to ML"
    #       file: index.qmd
    #     - text: "2.2 Neural Networks"
    #       file: index.qmd 
    # - part: "Lecture 9: Policy Gradients"
    #   chapters:
    #     - text: "2.1 Introduction to ML"
    #       file: index.qmd
    #     - text: "2.2 Neural Networks"
    #       file: index.qmd    
    # - part: "Lecture 10: Advanced Policy Gradients"
    #   chapters:
    #     - text: "2.1 Introduction to ML"
    #       file: index.qmd
    #     - text: "2.2 Neural Networks"
    #       file: index.qmd   
    # - part: "Lecture 11: Monte Carlo Tree Search"
    #   chapters:
    #     - text: "2.1 Introduction to ML"
    #       file: index.qmd
    #     - text: "2.2 Neural Networks"
    #       file: index.qmd

bibliography: references.bib

format:
  html:
    bread-crumbs: false
    number-sections: false
    grid:
      body-width: 1000px
      sidebar-width: 320px
    theme:
      - cosmo
      - brand
  pdf:
    documentclass: scrreprt

filters:
  - pseudocode