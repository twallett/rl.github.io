[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DATS 6450 – Reinforcement Learning",
    "section": "",
    "text": "Breakout (Lecture 8)\n    \n    \n      \n      Cheetah (Lecture 10)\n    \n    \n      \n      Gridworld (Lectures 4-6)\n    \n    \n      \n      Highway (Lecture 8)\n    \n  \n\n\n\n\n\nInstructor Information\n\n\n\n\n\n\nName: Tyler Wallett, M.S.\n\nTerm: Fall 2025\n\nOffice location: Samson Hall Room 310\n\nOffice hours: TBD\nE-mail: twallett@gwu.edu\n\nGithub: twallett\n\nZoom: Meeting Link\n\n\n\n\n\nCourse Description\nThe aim of this course is to provide a comprehensive understanding of the reinforcement learning framework. The course will explore the key distinctions between reinforcement learning and other artificial intelligence learning paradigms, delve into relevant industry applications, and examine both classical and deep learning approaches. Additionally, the course will cover the taxonomy of reinforcement learning and offer hands-on experience through practical implementations using OpenAI Gymnasium and other learning environments.\nThe classical approach will focus on learning methods designed to find optimal solutions in tabular environments, whereas the deep learning approach will tackle the challenge of finding approximate optimal solutions in large or continuous environments through the use of deep learning architectures.\nThe course will introduce the taxonomy of reinforcement learning by focusing on model-free value-based methods, transitioning to value function approximation and deep learning approaches, followed by novel policy-based methods using state-of-the-art architectures to tackle complex environments.\nTo conclude, a discussion on advanced topics, applications, and outlook of reinforcement learning will be provided.\n\n\nLearning Outcomes\n\nImplement Reinforcemeent Learning frameworks using NumPy and TensorFlow. \nDesign decision-making systems using classical and deep learning architectures. \nExplain Reinforcement Learning taxonomy. \nIdentify Reinforcement Learning’s challenges, current research, and future outlook.\n\n\n\nResources\n\nReinforcement Learning: An Introduction by Richard S. Sutton and Andrew G. Barto (Web Link)\nReinforcement Learning GitHub: Extra Materials\n\n\n\nSoftware Requirements\n\nProgramming: Python.\n\npip install numpy\npip install tensorflow\npip install pygame\npip install gymnasium\npip install stable-baselines3\n\nCloud Services: AWS & GCP virtual machines.\n\n\n\nCourse Outline\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nQuiz/Exams\nSubjects\n\n\n\n\nAug 29, 2025\nIntroduction to Reinforcement Learning\n\n- Course Outline  - What is Reinforcement Learning?  - Industry Applications  - Taxonomy \n\n\nSep 5, 2025\nMathematical Foundations\n\n- Set Theory  - Axiomatic Probability  - Conditioning  - Independence  - Random Variables  - Expectation  - Probability Distribution\n\n\nSep 12, 2025\nMulti-Armed Bandits\nQuiz 1\n- Exploration vs. Exploitation  - \\(\\epsilon\\)-Greedy  - Upper Confidence Boundary (UCB)  - Thompson Sampling\n\n\nSep 19, 2025\nDynamic Programming\nQuiz 2\n- Markov Chain  - Markov Decision Process  - Value Functions  - Action Value Functions  - Bellman Equations  - Value Iteration\n\n\nSep 26, 2025\nMonte Carlo Methods\nQuiz 3\n- OpenAI Gymansium Environment: GridWorld  - On-Policy Monte Carlo  - Off-Policy Monte Carlo\n\n\nOct 3, 2025\nTemporal-Difference\nQuiz 4\n- OpenAI Gymansium Environment: GridWorld  - Temporal Difference Prediction  - SARSA  - Q-Learning  - Double Q-Learning  - (Optional) n-step TD\n\n\nOct 10, 2025\nFunction Approximation\nExam 1\n- OpenAI Gymansium Environment: MountainCar  - Value Function Approximation (VFA)  - On-Policy Function Approximation  - Semi-gradient SARSA  - Limitations of Off-Policy Function Approximation\n\n\nOct 24, 2025\nDeep Q-Networks\nQuiz 5\n- OpenAI Gymansium Environment: BreakOut  - Multi-Layered Perceprtons (MLPs)  - Convolutional Neural Networks (CNNs)  - Experience Replay  - Fixed Targets  - Vanilla Deep Q-Network\n\n\nOct 31, 2025\nPolicy Gradients\nQuiz 6\n- OpenAI Gymansium Environment: CartPole  - Policy Gradient Theorem  - Vanilla Policy Gradient\n\n\nNov 7, 2025\nAdvanced Policy Gradients\nQuiz 7\n- OpenAI Gymansium Environment: HalfCheetah  - Trust Region Policy Optimization (TRPO)  - Proximal Policy Optimization: KL-Divergence  - Proximal Policy Optimization: Clip\n\n\nNov 14, 2025\nThanksgiving Break\n\n\n\n\nNov 21, 2025\nMonte Carlo Tree Search\nExam 2\n- OpenAI Gymansium Environment: Tic Tac Toe  - Model-based Reinforcement Learning  - Monte Carlo Tree Search  - AlphaGo  - MuZero\n\n\nOct 28, 2025\nConclusion\n\n\n\n\nDec 5, 2025\nFinal Project Submission\n\n\n\n\n\n\n\nPrerequisites\n\nDATS 6101 - Introduction to Data Science\n\n\n\nAssignments & Grading\n\n\n\nAssignment\nPoints\n\n\n\n\nQuizzes (5 best scores)\n25\n\n\nExam 1\n25\n\n\nExam 2\n25\n\n\nFinal Project\n25\n\n\n\n\n\nAverage Learning Per Week\n\n\n\n\n\n\nNote\n\n\n\nStudents are expected to spend a minimum of 100 minutes of out-of-class work for every 50 minutes of direct instruction, for a minimum total of 2.5 hours a week. A 3-credit course should include 2.5 hours of direct instruction and a minimum of 5 hours of independent learning or 7.5 hours per week.\n\n\n\n\nOnline Resources\n\n\n\n\n\n\nNote\n\n\n\nFor technical requirements and support, student services, obtaining a GWorld card, and state contact information please check HERE\n\n\n\n\nClassroom Recording\n\n\n\n\n\n\nNote\n\n\n\nThe particular class recordings will be available to students who are registered on an individual basis, upon request. Please let me know in advance if you have any medical issues or emergencies that will prevent you from joining the class.\n\n\n\n\nVirtual Academic Support\n\n\n\n\n\n\nTip\n\n\n\nA full range of academic support is offered virtually in fall 2020. See HERE for updates. Tutoring and course review sessions are offered through Academic Commons in an online format. See HERE. Writing and research consultations are available online. See HERE. Coaching, offered through the Office of Student Success, is available in a virtual format. See HERE. Academic Commons offers several short videos addressing different virtual learning strategies for the unique circumstances of the fall 2020 semester. See HERE. They also offer a variety of live virtual workshops to equip students with the tools they need to succeed in a virtual environment. See HERE.\n\n\n\n\nSafety and Security\n\n\n\n\n\n\nWarning\n\n\n\nIn an emergency: call GWPD 202-994-6111 or 911. For situation-specific actions: review the Emergency Response Handbook in HERE. In an active violence situation: Get Out, Hide Out, or Take Out. See HERE. Stay informed: safety.gwu.edu/stay-informed.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>DATS 6450 – Reinforcement Learning</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-2.html",
    "href": "lecture1/lecture1-2.html",
    "title": "Industry Applications",
    "section": "",
    "text": "Recommendation Systems\n\n\nTrained using MAB (Lecture 2)\nLink to Online Article\n\n\n\nGames\n\n\nTrained using DQN (Lecture 9)\nLink to Research Paper\n\n\n\nRobotics\n\n\nTrained using PPO (Lecture 11)\nLink to Blog\n\n\n\nAutonomous Vehicles\n\n   Partly trained using PPO (Lecture 11)\n\n\n\nNatural Language Processing\n\n\nTrained using PPO (Lecture 11)\nLink to Research Paper\n\n\n\nFinance\n\n\nTrained using PPO (Lecture 11)\nLink to Research Paper",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1.2 Industry Applications</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-2.html#recommendation-systems",
    "href": "lecture1/lecture1-2.html#recommendation-systems",
    "title": "Industry Applications",
    "section": "",
    "text": "Trained using MAB (Lecture 2)\nLink to Online Article",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1.2 Industry Applications</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-2.html#games",
    "href": "lecture1/lecture1-2.html#games",
    "title": "Industry Applications",
    "section": "Games",
    "text": "Games\n\n\nTrained using DQN (Lecture 9)\nLink to Research Paper",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1.2 Industry Applications</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-2.html#robotics",
    "href": "lecture1/lecture1-2.html#robotics",
    "title": "Industry Applications",
    "section": "Robotics",
    "text": "Robotics\n\n\nTrained using PPO (Lecture 11)\nLink to Video",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1.2 Industry Applications</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-2.html#autonomous-vehicles",
    "href": "lecture1/lecture1-2.html#autonomous-vehicles",
    "title": "Industry Applications",
    "section": "Autonomous Vehicles",
    "text": "Autonomous Vehicles\n\n\nPartly trained using PPO (Lecture 11)\nLink to Video",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1.2 Industry Applications</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-2.html#natural-language-processing",
    "href": "lecture1/lecture1-2.html#natural-language-processing",
    "title": "Industry Applications",
    "section": "Natural Language Processing",
    "text": "Natural Language Processing\n\n\nTrained using PPO (Lecture 11)\nLink to Research Paper",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1.2 Industry Applications</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-2.html#finance",
    "href": "lecture1/lecture1-2.html#finance",
    "title": "Industry Applications",
    "section": "Finance",
    "text": "Finance\n\n\nTrained using PPO (Lecture 11)\nLink to Research Paper",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1.2 Industry Applications</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html",
    "href": "lecture1/lecture1-1.html",
    "title": "What is Reinforcement Learning?",
    "section": "",
    "text": "“Learning Optimal Sequential Decision-Making”",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#what-is-reinforcement-learning",
    "href": "lecture1/lecture1-1.html#what-is-reinforcement-learning",
    "title": "What is Reinforcement Learning?",
    "section": "",
    "text": "Learning optimal sequential decision-making.",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#evaluative-feedback",
    "href": "lecture1/lecture1-1.html#evaluative-feedback",
    "title": "What is Reinforcement Learning?",
    "section": "",
    "text": "Evaluative feedback indicates how good the action taken was, but not whether it was the best or the worst action.\n\n\nIntuition: Learning through experience.\n\n\n\n Learning to Walk\n\n Ethics (Right vs. Wrong)",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#instructive-feedback",
    "href": "lecture1/lecture1-1.html#instructive-feedback",
    "title": "What is Reinforcement Learning?",
    "section": "Instructive Feedback",
    "text": "Instructive Feedback\n\nInstructive feedback indicates the correct action to take, independently of the action actually taken.\n\n\nIntuition: Learning through ground truth.\n\n\n\\(\\nabla f(x)\\)\nSupervised and Unsupervised Learning\n\n\nReinforcement Learning uses evaluative feedback, whereas Supervised / Unsupervised Learning uses instructive feedback.\n\n\n\n “Here’s some examples, now learn patterns in these examples…”\n\n “Here’s an environment, now learn patterns by exploring it…”",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#reinforcement-learning",
    "href": "lecture1/lecture1-1.html#reinforcement-learning",
    "title": "What is Reinforcement Learning?",
    "section": "Reinforcement Learning",
    "text": "Reinforcement Learning\n\nReinforcement Learning uses evaluative feedback, whereas Supervised / Unsupervised Learning uses instructive feedback.\n\n\n\n “Here’s some examples, now learn patterns in these examples…”\n\n “Here’s an environment, now learn patterns by exploring it…”",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#what-is-reinforcement-learning-1",
    "href": "lecture1/lecture1-1.html#what-is-reinforcement-learning-1",
    "title": "What is Reinforcement Learning?",
    "section": "What is Reinforcement Learning?",
    "text": "What is Reinforcement Learning?\n\nLearning optimal sequential decision-making.",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#optimal",
    "href": "lecture1/lecture1-1.html#optimal",
    "title": "What is Reinforcement Learning?",
    "section": "Optimal",
    "text": "Optimal\n\nMaximizing discounted sum of rewards, or goal \\(G\\).\nOptimal Value Functions \\(V^{*}\\).\nOptimal Action-Value Functions \\(Q^{*}\\).\nOptimal Policies \\(\\pi^{*}\\).\nBalancing exploration vs. exploitation trade-off.",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#what-is-reinforcement-learning-2",
    "href": "lecture1/lecture1-1.html#what-is-reinforcement-learning-2",
    "title": "What is Reinforcement Learning?",
    "section": "What is Reinforcement Learning?",
    "text": "What is Reinforcement Learning?\n\nLearning optimal sequential decision-making.",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#sequential-decision-making",
    "href": "lecture1/lecture1-1.html#sequential-decision-making",
    "title": "What is Reinforcement Learning?",
    "section": "Sequential Decision-Making",
    "text": "Sequential Decision-Making\n\n\n\n\nMarkov Decision Process\n\n\n\n\n\\(\\pi: S_{0}, A_{0}, R_{1}, S_{1}, A_{1}, R_{2}, ... , S_{T-1}, A_{T-1}, R_{T}\\)\n\n\nThe agent will make a series of actions over time.\nThese actions influence not only immediate rewards but also future states and rewards.",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  },
  {
    "objectID": "lecture1/lecture1-1.html#learning",
    "href": "lecture1/lecture1-1.html#learning",
    "title": "What is Reinforcement Learning?",
    "section": "Learning",
    "text": "Learning\n\nEvaluative Feedback\n\nEvaluative feedback indicates how good the action taken was, but not whether it was the best or the worst action.\n\n\nIntuition: Learning through experience.\n\n\n\n Learning to Walk\n\n Ethics (Right vs. Wrong)\n\n\n\n\nInstructive Feedback\n\nInstructive feedback indicates the correct action to take, independently of the action actually taken.\n\n\nIntuition: Learning through ground truth.\n\n\n\\(\\nabla f(x)\\)\nSupervised and Unsupervised Learning\n\n\nReinforcement Learning uses evaluative feedback, whereas Supervised / Unsupervised Learning uses instructive feedback.\n\n\n\n “Here’s some examples, now learn patterns in these examples…”\n\n “Here’s an environment, now learn patterns by exploring it…”",
    "crumbs": [
      "Lecture 1: Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>1.1 What is Reinforcement Learning?</span>"
    ]
  }
]